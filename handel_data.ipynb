{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "## SET CORRECT VALUES FIRST!!\n",
    "file_csv = \"HIMU-2021-12-10_14-57-10.csv\"\n",
    "user = 6 #user\n",
    "exp = 10\n",
    "device_is_s8 = True #true = s8, false = s7\n",
    "## Thanks\n",
    "\n",
    "df = pd.read_csv(file_csv, parse_dates=True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'],unit='ms')\n",
    "\n",
    "s8 = {\n",
    "    \"acc\": [\"lsm6dsl_acceleration_sensor.x\", \"lsm6dsl_acceleration_sensor.y\", \"lsm6dsl_acceleration_sensor.z\"],\n",
    "    \"gyr\": [\"lsm6dsl_gyroscope_sensor.x\", \"lsm6dsl_gyroscope_sensor.y\", \"lsm6dsl_gyroscope_sensor.z\"]\n",
    "}\n",
    "\n",
    "s7 = {\n",
    "    \"acc\": [\"k6ds3tr_acceleration_sensor.x\", \"k6ds3tr_acceleration_sensor.y\", \"k6ds3tr_acceleration_sensor.z\"],\n",
    "    \"gyr\": [\"k6ds3tr_gyroscope_sensor.x\", \"k6ds3tr_gyroscope_sensor.y\", \"k6ds3tr_gyroscope_sensor.z\"]\n",
    "}\n",
    "device = s7\n",
    "if device_is_s8:\n",
    "    device = s8\n",
    "\n",
    "file_name = f\"raw data/acc_exp{exp:02d}_user{user:02d}_device{'S8' if device_is_s8 else 'S7'}.txt\"\n",
    "my_file = open(file_name, 'w')\n",
    "for index, row in df.iterrows():\n",
    "    my_file.write(f\"{row[device['acc'][0]]} {row[device['acc'][1]]} {row[device['acc'][2]]}\\n\")\n",
    "my_file.close()\n",
    "\n",
    "file_name = f\"raw data/gyro_exp{exp:02d}_user{user:02d}_device{'S8' if device_is_s8 else 'S7'}.txt\"\n",
    "my_file = open(file_name, 'w')\n",
    "for index, row in df.iterrows():\n",
    "    my_file.write(f\"{row[device['gyr'][0]]} {row[device['gyr'][1]]} {row[device['gyr'][2]]}\\n\")\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- 'RawData/labels.txt': include all the activity labels available for the dataset (1 per row).\n",
    "   Column 1: experiment number ID,\n",
    "   Column 2: user number ID,\n",
    "   Column 3: activity number ID\n",
    "   Column 4: Label start point (in number of signal log samples (recorded at 50Hz))\n",
    "   Column 5: Label end point (in number of signal log samples)\n",
    "\n",
    "activity_type:\n",
    "1 WALKING\n",
    "2 WALKING_UPSTAIRS\n",
    "3 WALKING_DOWNSTAIRS\n",
    "4 SITTING\n",
    "5 STANDING\n",
    "\"\"\"\n",
    "file_name_lab = f\"labels_{'S8' if device_is_s8 else 'S7'}.txt\"\n",
    "\n",
    "activity_start = datetime.fromisoformat(\"2021-12-10 14:10:25\") # Settes EN time tilbake fra log\n",
    "activity_end = datetime.fromisoformat(\"2021-12-10 14:11:25\") # \"2021-12-09T08:31:15.000Z\"\n",
    "activity_type = 4 #between 1-5\n",
    "\n",
    "val = df[(df['timestamp'] > activity_start) & (df['timestamp'] < activity_end)]\n",
    "\n",
    "with open('raw data/labels.txt', \"a\") as a_file:\n",
    "    a_file.write(f\"{exp} {user} {activity_type} {val.iloc[0].name} {val.iloc[-1].name}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from decimal import ROUND_HALF_UP, Decimal\n",
    "from logging import getLogger\n",
    "import math\n",
    "import traceback\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "from scipy import stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import butter, filtfilt\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from statsmodels.regression.linear_model import burg\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self, fs: int = 50) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            fs (int, default=50): Sampling frequency of sensor signals\n",
    "        \"\"\"\n",
    "        self.fs = fs\n",
    "\n",
    "    def apply_filter(\n",
    "            self, signal: pd.DataFrame, filter: str = \"median\", window: int = 5\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"A denosing filter is applied to remove noise in signals.\n",
    "        Args:\n",
    "            signal (pd.DataFrame): Raw signal\n",
    "            filter (str, default='median'): Filter name is chosen from 'mean', 'median', or 'butterworth'\n",
    "            window (int, default=5): Length of filter\n",
    "        Returns:\n",
    "            signal (pd.DataFrame): Filtered signal\n",
    "        See Also:\n",
    "            'butterworth' applies a 3rd order low-pass Butterworth filter with a corner frequency of 20 Hz.\n",
    "        \"\"\"\n",
    "        if filter == \"mean\":\n",
    "            signal = signal.rolling(window=window, center=True, min_periods=1).mean()\n",
    "        elif filter == \"median\":\n",
    "            signal = signal.rolling(window=window, center=True, min_periods=1).median()\n",
    "        elif filter == \"butterworth\":\n",
    "            fc = 20  # cutoff frequency\n",
    "            w = fc / (self.fs / 2)  # Normalize the frequency\n",
    "            b, a = butter(3, w, \"low\")  # 3rd order low-pass Butterworth filter\n",
    "            signal = pd.DataFrame(filtfilt(b, a, signal, axis=0), columns=signal.columns)\n",
    "        else:\n",
    "            try:\n",
    "                raise ValueError(\"Not defined filter. See Args.\")\n",
    "            except ValueError:\n",
    "                logger.error(traceback.format_exc())\n",
    "\n",
    "        return signal\n",
    "\n",
    "    def normalize(self, signal: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply normalization\n",
    "        Args:\n",
    "            signal (pd.DataFrame): Raw signal\n",
    "        Returns:\n",
    "            signal (pd.DataFrame): Normalized signal\n",
    "        \"\"\"\n",
    "        df_mean = signal.mean()\n",
    "        df_std = signal.std()\n",
    "        signal = (signal - df_mean) / df_std\n",
    "        return signal\n",
    "\n",
    "    def segment_signal(\n",
    "            self,\n",
    "            signal: pd.DataFrame,\n",
    "            window_size: int = 128,\n",
    "            overlap_rate: int = 0.5,\n",
    "            res_type: str = \"dataframe\",\n",
    "    ) -> List[pd.DataFrame]:\n",
    "        \"\"\"Sample sensor signals in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window).\n",
    "        Args:\n",
    "            signal (pandas.DataFrame): Raw signal\n",
    "            window_size (int, default=128): Window size of sliding window to segment raw signals.\n",
    "            overlap_rate (float, default=0.5): Overlap rate of sliding window to segment raw signals.\n",
    "            res_type (str, default='dataframe'): Type of return value; 'array' or 'dataframe'\n",
    "        Returns:\n",
    "            signal_seg (list of pandas.DataFrame): List of segmented sigmal.\n",
    "        \"\"\"\n",
    "        signal_seg = []\n",
    "\n",
    "        for start_idx in range(0, len(signal) - window_size, int(window_size * overlap_rate)):\n",
    "            seg = signal.iloc[start_idx : start_idx + window_size].reset_index(drop=True)\n",
    "            if res_type == \"array\":\n",
    "                seg = seg.values\n",
    "            signal_seg.append(seg)\n",
    "\n",
    "        if res_type == \"array\":\n",
    "            signal_seg = np.array(signal_seg)\n",
    "\n",
    "        return signal_seg\n",
    "\n",
    "    def separate_gravity(self, acc: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Separate acceleration signal into body and gravity acceleration signal.\n",
    "        Another low pass Butterworth filter with a corner frequency of 0.3 Hz is applied.\n",
    "        Args:\n",
    "            acc (pd.DataFrame): Segmented acceleration signal\n",
    "        Returns:\n",
    "            acc_body (pd.DataFrame): Body acceleration signal\n",
    "            acc_grav (pd.DataFrame): Gravity acceleration signal\n",
    "        \"\"\"\n",
    "        fc = 0.3  # cutoff frequency\n",
    "        w = fc / (self.fs / 2)  # Normalize the frequency\n",
    "        b, a = butter(3, w, \"low\")  # 3rd order low pass Butterworth filter\n",
    "        acc_grav = pd.DataFrame(\n",
    "            filtfilt(b, a, acc, axis=0), columns=acc.columns\n",
    "        )  # Apply Butterworth filter\n",
    "\n",
    "        # Substract gravity acceleration from acceleration sigal.\n",
    "        acc_body = acc - acc_grav\n",
    "        return acc_body, acc_grav\n",
    "\n",
    "    def obtain_jerk_signal(self, signal: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Derive signal to obtain Jerk signals\n",
    "        Args:\n",
    "            signal (pd.DataFrame)\n",
    "        Returns:\n",
    "            jerk_signal (pd.DataFrame):\n",
    "        \"\"\"\n",
    "        jerk_signal = signal.diff(periods=1)  # Calculate difference\n",
    "        jerk_signal.iloc[0] = jerk_signal.iloc[1]  # Fillna\n",
    "        jerk_signal = jerk_signal / (1 / self.fs)  # Derive in time (1 / sampling frequency)\n",
    "        return jerk_signal\n",
    "\n",
    "    def obtain_magnitude(self, signal):\n",
    "        \"\"\"Calculate the magnitude of these three-dimensional signals using the Euclidean norm\n",
    "        Args:\n",
    "            signal (pandas.DataFrame): Three-dimensional signals\n",
    "        Returns:\n",
    "            res (pandas.DataFrame): Magnitude of three-dimensional signals\n",
    "        \"\"\"\n",
    "        return pd.DataFrame(norm(signal, ord=2, axis=1))\n",
    "\n",
    "    def obtain_spectrum(self, signal):\n",
    "        \"\"\"Obtain spectrum using Fast Fourier Transform (FFT).\n",
    "        Args:\n",
    "            signal (pandas.DataFrame): Time domain signals\n",
    "        Returns:\n",
    "            amp (pandas.DataFrame): Amplitude spectrum\n",
    "            phase (pandas.DataFrame): Phase spectrum\n",
    "        \"\"\"\n",
    "        N = len(signal)\n",
    "        columns = signal.columns\n",
    "\n",
    "        for col in columns:\n",
    "            signal[col] = signal[col] * np.hamming(N)  # hamming window\n",
    "\n",
    "        F = fft(signal, axis=0)  # Apply FFT\n",
    "        F = F[: N // 2, :]  # Remove the overlapping part\n",
    "\n",
    "        amp = np.abs(F)  # Obtain the amplitude spectrum\n",
    "        amp = amp / N * 2\n",
    "        amp[0] = amp[0] / 2\n",
    "        amp = pd.DataFrame(amp, columns=columns)  # Convert array to DataFrame\n",
    "        phase = np.angle(F)\n",
    "        phase = pd.DataFrame(phase, columns=columns)  # Convert array to DataFrame\n",
    "\n",
    "        return amp, phase\n",
    "\n",
    "    def obtain_ecdf_percentile(self, signal, n_bins=10):\n",
    "        \"\"\"Obtain ECDF (empirical cumulative distribution function) percentile values.\n",
    "        Args:\n",
    "            signal (DataFrame): Time domain signals\n",
    "            n_bins (int, default: 10): How many percentiles to use as a feature\n",
    "        Returns:\n",
    "            features (array): ECDF percentile values.\n",
    "        \"\"\"\n",
    "        idx = np.linspace(0, signal.shape[0] - 1, n_bins)  # Take n_bins linspace percentile.\n",
    "        idx = [int(Decimal(str(ix)).quantize(Decimal(\"0\"), rounding=ROUND_HALF_UP)) for ix in idx]\n",
    "        features = np.array([])\n",
    "        for col in signal.columns:\n",
    "            ecdf = ECDF(signal[col].values)  # fit\n",
    "            x = ecdf.x[1:]  # Remove -inf\n",
    "            feat = x[idx]\n",
    "            features = np.hstack([features, feat])\n",
    "\n",
    "        return features\n",
    "\n",
    "    def obtain_mean(self, signal) -> np.ndarray:\n",
    "        return signal.mean().values\n",
    "\n",
    "    def obtain_std(self, signal) -> np.ndarray:\n",
    "        return signal.std().values\n",
    "\n",
    "    def obtain_mad(self, signal) -> np.ndarray:\n",
    "        return stats.median_abs_deviation(signal, scale=1/1.4826)\n",
    "        #return stats.median_absolute_deviation(signal, axis=0)\n",
    "\n",
    "    def obtain_max(self, signal) -> np.ndarray:\n",
    "        return signal.max().values\n",
    "\n",
    "    def obtain_min(self, signal) -> np.ndarray:\n",
    "        return signal.min().values\n",
    "\n",
    "    def obtain_sma(self, signal, window_size=128) -> np.ndarray:\n",
    "        window_second = window_size / self.fs\n",
    "        return sum(signal.sum().values - self.obtain_min(signal) * len(signal)) / window_second\n",
    "\n",
    "    def obtain_energy(self, signal) -> np.ndarray:\n",
    "        return norm(signal, ord=2, axis=0) ** 2 / len(signal)\n",
    "\n",
    "    def obtain_iqr(self, signal) -> np.ndarray:\n",
    "        return signal.quantile(0.75).values - signal.quantile(0.25).values\n",
    "\n",
    "    def obtain_entropy(self, signal) -> np.ndarray:\n",
    "        signal = signal - signal.min()\n",
    "        return stats.entropy(signal)\n",
    "\n",
    "    def obtain_arCoeff(self, signal) -> np.ndarray:\n",
    "        arCoeff = np.array([])\n",
    "        for col in signal.columns:\n",
    "            val, _ = burg(signal[col], order=4)\n",
    "            arCoeff = np.hstack((arCoeff, val))\n",
    "        return arCoeff\n",
    "\n",
    "    def obtain_correlation(self, signal) -> np.ndarray:\n",
    "        if signal.shape[1] == 1:  # Signal dimension is 1\n",
    "            correlation = np.array([])\n",
    "        else:  # Signal dimension is 3\n",
    "            xy = np.corrcoef(signal[\"x\"], signal[\"y\"])[0][1]\n",
    "            yz = np.corrcoef(signal[\"y\"], signal[\"z\"])[0][1]\n",
    "            zx = np.corrcoef(signal[\"z\"], signal[\"x\"])[0][1]\n",
    "            correlation = np.hstack((xy, yz, zx))\n",
    "        return correlation\n",
    "\n",
    "    def obtain_maxInds(self, signal) -> np.ndarray:\n",
    "        return signal.idxmax().values\n",
    "\n",
    "    def obtain_meanFreq(self, signal) -> np.ndarray:\n",
    "        meanFreq = np.array([])\n",
    "        for col in signal.columns:\n",
    "            val = np.mean(signal[col] * np.arange(len(signal)))\n",
    "            meanFreq = np.hstack((meanFreq, val))\n",
    "        return meanFreq\n",
    "\n",
    "    def obtain_skewness(self, signal) -> np.ndarray:\n",
    "        return signal.skew().values\n",
    "\n",
    "    def obtain_kurtosis(self, signal) -> np.ndarray:\n",
    "        return signal.kurt().values\n",
    "\n",
    "    def obtain_bandsEnergy(self, signal) -> np.ndarray:\n",
    "        bandsEnergy = np.array([])\n",
    "        bins = [0, 4, 8, 12, 16, 20, 24, 29, 34, 39, 44, 49, 54, 59, 64]\n",
    "        for i in range(len(bins) - 1):\n",
    "            df = signal.iloc[bins[i] : bins[i + 1]]\n",
    "            arr = self.obtain_energy(df)\n",
    "            bandsEnergy = np.hstack((bandsEnergy, arr))\n",
    "        return bandsEnergy\n",
    "\n",
    "    def obtain_angle(self, v1, v2) -> np.ndarray:\n",
    "        length = lambda v: math.sqrt(np.dot(v, v))\n",
    "        return math.acos(np.dot(v1, v2) / (length(v1) * length(v2)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from src.data_prep.preprocessing import Preprocess  # Load class for obtaining features\n",
    "\n",
    "\n",
    "def create_features(acc_raw: pd.DataFrame, gyro_raw: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Create features from raw acceleration and gyroscope sensor data\n",
    "    Args:\n",
    "        acc_raw (pd.DataFrame): Raw 3-axial accelerometer signals with columns denoting axes.\n",
    "        gyro_raw (pd.DataFrame): Raw 3-axial gyroscope signals with columns denoting axes.\n",
    "    Returns:\n",
    "        features (np.ndarray): Created features corresponding args with columns denoting feature names.\n",
    "    \"\"\"\n",
    "    of = Preprocess(fs=50)  # Create an instance.\n",
    "\n",
    "    # Remove noises by median filter & Butterworth filter\n",
    "    acc_raw = of.apply_filter(signal=acc_raw, filter=\"median\", window=5)\n",
    "    acc_raw = of.apply_filter(signal=acc_raw, filter=\"butterworth\")\n",
    "    gyro_raw = of.apply_filter(signal=gyro_raw, filter=\"median\", window=5)\n",
    "    gyro_raw = of.apply_filter(signal=gyro_raw, filter=\"butterworth\")\n",
    "\n",
    "    # Sample signals in fixed-width sliding windows\n",
    "    tAccXYZ = of.segment_signal(acc_raw, window_size=128, overlap_rate=0.5, res_type=\"dataframe\")\n",
    "    tBodyGyroXYZ = of.segment_signal(\n",
    "        gyro_raw, window_size=128, overlap_rate=0.5, res_type=\"dataframe\"\n",
    "    )\n",
    "\n",
    "    # Separate acceleration signal into body and gravity acceleration signal\n",
    "    tBodyAccXYZ, tGravityAccXYZ = [], []\n",
    "    for acc in tAccXYZ:\n",
    "        body_acc, grav_acc = of.separate_gravity(acc.copy())\n",
    "        tBodyAccXYZ.append(body_acc)\n",
    "        tGravityAccXYZ.append(grav_acc)\n",
    "\n",
    "    # Obtain Jerk signals of body linear acceleration and angular velocity\n",
    "    tBodyAccJerkXYZ, tBodyGyroJerkXYZ = [], []\n",
    "    for body_acc, gyro in zip(tBodyAccXYZ, tBodyGyroXYZ):\n",
    "        body_acc_jerk = of.obtain_jerk_signal(body_acc.copy())\n",
    "        gyro_jerk = of.obtain_jerk_signal(gyro.copy())\n",
    "\n",
    "        tBodyAccJerkXYZ.append(body_acc_jerk)\n",
    "        tBodyGyroJerkXYZ.append(gyro_jerk)\n",
    "\n",
    "    # Calculate the magnitude of three-dimensional signals using the Euclidean norm\n",
    "    tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag = (\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "    )\n",
    "    for body_acc, grav_acc, body_acc_jerk, gyro, gyro_jerk in zip(\n",
    "            tBodyAccXYZ, tGravityAccXYZ, tBodyAccJerkXYZ, tBodyGyroXYZ, tBodyGyroJerkXYZ\n",
    "    ):\n",
    "        body_acc_mag = of.obtain_magnitude(body_acc.copy())\n",
    "        grav_acc_mag = of.obtain_magnitude(grav_acc.copy())\n",
    "        body_acc_jerk_mag = of.obtain_magnitude(body_acc_jerk.copy())\n",
    "        gyro_mag = of.obtain_magnitude(gyro.copy())\n",
    "        gyro_jerk_mag = of.obtain_magnitude(gyro_jerk.copy())\n",
    "\n",
    "        tBodyAccMag.append(body_acc_mag)\n",
    "        tGravityAccMag.append(grav_acc_mag)\n",
    "        tBodyAccJerkMag.append(body_acc_jerk_mag)\n",
    "        tBodyGyroMag.append(gyro_mag)\n",
    "        tBodyGyroJerkMag.append(gyro_jerk_mag)\n",
    "\n",
    "    # Obtain amplitude spectrum using Fast Fourier Transform (FFT).\n",
    "    (\n",
    "        fBodyAccXYZAmp,\n",
    "        fBodyAccJerkXYZAmp,\n",
    "        fBodyGyroXYZAmp,\n",
    "        fBodyAccMagAmp,\n",
    "        fBodyAccJerkMagAmp,\n",
    "        fBodyGyroMagAmp,\n",
    "        fBodyGyroJerkMagAmp,\n",
    "    ) = ([], [], [], [], [], [], [])\n",
    "    (\n",
    "        fBodyAccXYZPhs,\n",
    "        fBodyAccJerkXYZPhs,\n",
    "        fBodyGyroXYZPhs,\n",
    "        fBodyAccMagPhs,\n",
    "        fBodyAccJerkMagPhs,\n",
    "        fBodyGyroMagPhs,\n",
    "        fBodyGyroJerkMagPhs,\n",
    "    ) = ([], [], [], [], [], [], [])\n",
    "    for (\n",
    "            body_acc,\n",
    "            body_acc_jerk,\n",
    "            gyro,\n",
    "            body_acc_mag,\n",
    "            body_acc_jerk_mag,\n",
    "            gyro_mag,\n",
    "            gyro_jerk_mag,\n",
    "    ) in zip(\n",
    "        tBodyAccXYZ,\n",
    "        tBodyAccJerkXYZ,\n",
    "        tBodyGyroXYZ,\n",
    "        tBodyAccMag,\n",
    "        tBodyAccJerkMag,\n",
    "        tBodyGyroMag,\n",
    "        tBodyGyroJerkMag,\n",
    "    ):\n",
    "        body_acc_amp, body_acc_phase = of.obtain_spectrum(body_acc.copy())\n",
    "        body_acc_jerk_amp, body_acc_jerk_phase = of.obtain_spectrum(body_acc_jerk.copy())\n",
    "        gyro_amp, gyro_phase = of.obtain_spectrum(gyro.copy())\n",
    "        body_acc_mag_amp, body_acc_mag_phase = of.obtain_spectrum(body_acc_mag.copy())\n",
    "        body_acc_jerk_mag_amp, body_acc_jerk_mag_phase = of.obtain_spectrum(\n",
    "            body_acc_jerk_mag.copy()\n",
    "        )\n",
    "        gyro_mag_amp, gyro_mag_phase = of.obtain_spectrum(gyro_mag.copy())\n",
    "        gyro_jerk_mag_amp, gyro_jerk_mag_phase = of.obtain_spectrum(gyro_jerk_mag.copy())\n",
    "\n",
    "        fBodyAccXYZAmp.append(body_acc_amp)\n",
    "        fBodyAccJerkXYZAmp.append(body_acc_jerk_amp)\n",
    "        fBodyGyroXYZAmp.append(gyro_amp)\n",
    "        fBodyAccMagAmp.append(body_acc_mag_amp)\n",
    "        fBodyAccJerkMagAmp.append(body_acc_jerk_mag_amp)\n",
    "        fBodyGyroMagAmp.append(gyro_mag_amp)\n",
    "        fBodyGyroJerkMagAmp.append(gyro_jerk_mag_amp)\n",
    "\n",
    "        fBodyAccXYZPhs.append(body_acc_phase)\n",
    "        fBodyAccJerkXYZPhs.append(body_acc_jerk_phase)\n",
    "        fBodyGyroXYZPhs.append(gyro_phase)\n",
    "        fBodyAccMagPhs.append(body_acc_mag_phase)\n",
    "        fBodyAccJerkMagPhs.append(body_acc_jerk_mag_phase)\n",
    "        fBodyGyroMagPhs.append(gyro_mag_phase)\n",
    "        fBodyGyroJerkMagPhs.append(gyro_jerk_mag_phase)\n",
    "\n",
    "    #  Following signals are obtained by implementing above functions.\n",
    "    time_signals = [\n",
    "        tBodyAccXYZ,\n",
    "        tGravityAccXYZ,\n",
    "        tBodyAccJerkXYZ,\n",
    "        tBodyGyroXYZ,\n",
    "        tBodyGyroJerkXYZ,\n",
    "        tBodyAccMag,\n",
    "        tGravityAccMag,\n",
    "        tBodyAccJerkMag,\n",
    "        tBodyGyroMag,\n",
    "        tBodyGyroJerkMag,\n",
    "    ]\n",
    "    freq_signals = [\n",
    "        fBodyAccXYZAmp,\n",
    "        fBodyAccJerkXYZAmp,\n",
    "        fBodyGyroXYZAmp,\n",
    "        fBodyAccMagAmp,\n",
    "        fBodyAccJerkMagAmp,\n",
    "        fBodyGyroMagAmp,\n",
    "        fBodyGyroJerkMagAmp,\n",
    "        fBodyAccXYZPhs,\n",
    "        fBodyAccJerkXYZPhs,\n",
    "        fBodyGyroXYZPhs,\n",
    "        fBodyAccMagPhs,\n",
    "        fBodyAccJerkMagPhs,\n",
    "        fBodyGyroMagPhs,\n",
    "        fBodyGyroJerkMagPhs,\n",
    "    ]\n",
    "\n",
    "    all_signals = time_signals + freq_signals\n",
    "\n",
    "    # Calculate feature vectors by using signals\n",
    "    features = []\n",
    "\n",
    "    for i in range(len(tBodyAccXYZ)):\n",
    "        feature_vector = np.array([])\n",
    "\n",
    "        # mean, std, mad, max, min, sma, energy, iqr, entropy\n",
    "        for t_signal in all_signals:\n",
    "            sig = t_signal[i].copy()\n",
    "            mean = of.obtain_mean(sig)\n",
    "            std = of.obtain_std(sig)\n",
    "            mad = of.obtain_mad(sig)\n",
    "            max_val = of.obtain_max(sig)\n",
    "            min_val = of.obtain_min(sig)\n",
    "            sma = of.obtain_sma(sig)\n",
    "            energy = of.obtain_energy(sig)\n",
    "            iqr = of.obtain_iqr(sig)\n",
    "            entropy = of.obtain_entropy(sig)\n",
    "            feature_vector = np.hstack(\n",
    "                (feature_vector, mean, std, mad, max_val, min_val, sma, energy, iqr, entropy)\n",
    "            )\n",
    "\n",
    "        # arCoeff\n",
    "        for t_signal in time_signals:\n",
    "            sig = t_signal[i].copy()\n",
    "            arCoeff = of.obtain_arCoeff(sig)\n",
    "            feature_vector = np.hstack((feature_vector, arCoeff))\n",
    "\n",
    "        # correlation\n",
    "        for t_signal in [\n",
    "            tBodyAccXYZ,\n",
    "            tGravityAccXYZ,\n",
    "            tBodyAccJerkXYZ,\n",
    "            tBodyGyroXYZ,\n",
    "            tBodyGyroJerkXYZ,\n",
    "        ]:\n",
    "            sig = t_signal[i].copy()\n",
    "            correlation = of.obtain_correlation(sig)\n",
    "            feature_vector = np.hstack((feature_vector, correlation))\n",
    "\n",
    "        # maxInds, meanFreq, skewness, kurtosis\n",
    "        for t_signal in freq_signals:\n",
    "            sig = t_signal[i].copy()\n",
    "            maxInds = of.obtain_maxInds(sig)\n",
    "            meanFreq = of.obtain_meanFreq(sig)\n",
    "            skewness = of.obtain_skewness(sig)\n",
    "            kurtosis = of.obtain_kurtosis(sig)\n",
    "            feature_vector = np.hstack((feature_vector, maxInds, meanFreq, skewness, kurtosis))\n",
    "\n",
    "        # bandsEnergy\n",
    "        for t_signal in [tBodyAccXYZ, tBodyAccJerkXYZ, tBodyGyroXYZ]:\n",
    "            sig = t_signal[i].copy()\n",
    "            bandsEnergy = of.obtain_bandsEnergy(sig)\n",
    "            feature_vector = np.hstack((feature_vector, bandsEnergy))\n",
    "\n",
    "        # angle\n",
    "        gravityMean = tGravityAccXYZ[i].mean()\n",
    "        tBodyAccMean = tBodyAccXYZ[i].mean()\n",
    "        tBodyAccJerkMean = tBodyAccJerkXYZ[i].mean()\n",
    "        tBodyGyroMean = tBodyGyroXYZ[i].mean()\n",
    "        tBodyGyroJerkMean = tBodyGyroJerkXYZ[i].mean()\n",
    "        tXAxisAcc = tAccXYZ[i][\"x\"]\n",
    "        tXAxisGravity = tGravityAccXYZ[i][\"x\"]\n",
    "        tYAxisAcc = tAccXYZ[i][\"y\"]\n",
    "        tYAxisGravity = tGravityAccXYZ[i][\"y\"]\n",
    "        tZAxisAcc = tAccXYZ[i][\"z\"]\n",
    "        tZAxisGravity = tGravityAccXYZ[i][\"z\"]\n",
    "\n",
    "        tBodyAccWRTGravity = of.obtain_angle(tBodyAccMean, gravityMean)\n",
    "        tBodyAccJerkWRTGravity = of.obtain_angle(tBodyAccJerkMean, gravityMean)\n",
    "        tBodyGyroWRTGravity = of.obtain_angle(tBodyGyroMean, gravityMean)\n",
    "        tBodyGyroJerkWRTGravity = of.obtain_angle(tBodyGyroJerkMean, gravityMean)\n",
    "        tXAxisAccWRTGravity = of.obtain_angle(tXAxisAcc, tXAxisGravity)\n",
    "        tYAxisAccWRTGravity = of.obtain_angle(tYAxisAcc, tYAxisGravity)\n",
    "        tZAxisAccWRTGravity = of.obtain_angle(tZAxisAcc, tZAxisGravity)\n",
    "\n",
    "        feature_vector = np.hstack(\n",
    "            (\n",
    "                feature_vector,\n",
    "                tBodyAccWRTGravity,\n",
    "                tBodyAccJerkWRTGravity,\n",
    "                tBodyGyroWRTGravity,\n",
    "                tBodyGyroJerkWRTGravity,\n",
    "                tXAxisAccWRTGravity,\n",
    "                tYAxisAccWRTGravity,\n",
    "                tZAxisAccWRTGravity,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # ECDF\n",
    "        for t_signal in [tBodyAccXYZ, tBodyGyroXYZ]:\n",
    "            sig = t_signal[i].copy()\n",
    "            ecdf = of.obtain_ecdf_percentile(sig)\n",
    "            feature_vector = np.hstack((feature_vector, ecdf))\n",
    "\n",
    "        features.append(feature_vector)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def get_feature_names() -> List[str]:\n",
    "    \"\"\"Get feature names\n",
    "    Returns:\n",
    "        feature_names (List[str]): Title of features\n",
    "    \"\"\"\n",
    "    time_signal_names = [\n",
    "        \"tBodyAccXYZ\",\n",
    "        \"tGravityAccXYZ\",\n",
    "        \"tBodyAccJerkXYZ\",\n",
    "        \"tBodyGyroXYZ\",\n",
    "        \"tBodyGyroJerkXYZ\",\n",
    "        \"tBodyAccMag\",\n",
    "        \"tGravityAccMag\",\n",
    "        \"tBodyAccJerkMag\",\n",
    "        \"tBodyGyroMag\",\n",
    "        \"tBodyGyroJerkMag\",\n",
    "    ]\n",
    "    freq_signal_names = [\n",
    "        \"fBodyAccXYZAmp\",\n",
    "        \"fBodyAccJerkXYZAmp\",\n",
    "        \"fBodyGyroXYZAmp\",\n",
    "        \"fBodyAccMagAmp\",\n",
    "        \"fBodyAccJerkMagAmp\",\n",
    "        \"fBodyGyroMagAmp\",\n",
    "        \"fBodyGyroJerkMagAmp\",\n",
    "        \"fBodyAccXYZPhs\",\n",
    "        \"fBodyAccJerkXYZPhs\",\n",
    "        \"fBodyGyroXYZPhs\",\n",
    "        \"fBodyAccMagPhs\",\n",
    "        \"fBodyAccJerkMagPhs\",\n",
    "        \"fBodyGyroMagPhs\",\n",
    "        \"fBodyGyroJerkMagPhs\",\n",
    "    ]\n",
    "    all_signal_names = time_signal_names + freq_signal_names\n",
    "    feature_names = []\n",
    "\n",
    "    for name in all_signal_names:\n",
    "        for s in [\"Mean\", \"Std\", \"Mad\", \"Max\", \"Min\", \"Sma\", \"Energy\", \"Iqr\", \"Entropy\"]:\n",
    "            if s == \"Sma\":\n",
    "                feature_names.append(f\"{name}{s}\")\n",
    "                continue\n",
    "            if \"XYZ\" in name:\n",
    "                n = name.replace(\"XYZ\", \"\")\n",
    "                feature_names += [f\"{n}{s}-{ax}\" for ax in [\"X\", \"Y\", \"Z\"]]\n",
    "            else:\n",
    "                feature_names.append(f\"{name}{s}\")\n",
    "\n",
    "    for name in time_signal_names:\n",
    "        if \"XYZ\" in name:\n",
    "            n = name.replace(\"XYZ\", \"\")\n",
    "            feature_names += [f\"{n}ArCoeff-{ax}{i}\" for ax in [\"X\", \"Y\", \"Z\"] for i in range(4)]\n",
    "        else:\n",
    "            feature_names += [f\"{name}ArCoeff{i}\" for i in range(4)]\n",
    "\n",
    "    for name in [\n",
    "        \"tBodyAccXYZ\",\n",
    "        \"tGravityAccXYZ\",\n",
    "        \"tBodyAccJerkXYZ\",\n",
    "        \"tBodyGyroXYZ\",\n",
    "        \"tBodyGyroJerkXYZ\",\n",
    "    ]:\n",
    "        n = name.replace(\"XYZ\", \"\")\n",
    "        feature_names += [f\"{n}Correlation-{ax}\" for ax in [\"X\", \"Y\", \"Z\"]]\n",
    "\n",
    "    for name in freq_signal_names:\n",
    "        for s in [\"MaxInds\", \"MeanFreq\", \"Skewness\", \"Kurtosis\"]:\n",
    "            if \"XYZ\" in name:\n",
    "                n = name.replace(\"XYZ\", \"\")\n",
    "                feature_names += [f\"{n}{s}-{ax}\" for ax in [\"X\", \"Y\", \"Z\"]]\n",
    "            else:\n",
    "                feature_names.append(f\"{name}{s}\")\n",
    "\n",
    "    for name in [\"tBodyAccXYZ\", \"tBodyAccJerkXYZ\", \"tBodyGyroXYZ\"]:\n",
    "        n = name.replace(\"XYZ\", \"\")\n",
    "        feature_names += [f\"{n}BandsEnergy-{ax}{i}\" for i in range(14) for ax in [\"X\", \"Y\", \"Z\"]]\n",
    "\n",
    "    feature_names += [\n",
    "        \"tBodyAccWRTGravity\",\n",
    "        \"tBodyAccJerkWRTGravity\",\n",
    "        \"tBodyGyroWRTGravity\",\n",
    "        \"tBodyGyroJerkWRTGravity\",\n",
    "        \"tXAxisAccWRTGravity\",\n",
    "        \"tYAxisAccWRTGravity\",\n",
    "        \"tZAxisAccWRTGravity\",\n",
    "    ]\n",
    "\n",
    "    feature_names += [\n",
    "        f\"tBody{sensor}ECDF-{axis}{i}\"\n",
    "        for sensor in [\"Acc\", \"Gyro\"]\n",
    "        for axis in [\"X\", \"Y\", \"Z\"]\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    return feature_names\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andreas/Documents/git/dsProject/s8/logs/generate-features-20211212-210940/generate-features-20211212-210940.log\n",
      "/Users/andreas/Documents/git/dsProject/s8/logs/generate-features-20211212-210940/generate-features-20211212-210940.log\n",
      "/Users/andreas/Documents/git/dsProject/s8/logs/generate-features-20211212-210940/generate-features-20211212-210940.log\n",
      "/Users/andreas/Documents/git/dsProject/s8/logs/generate-features-20211212-210940/generate-features-20211212-210940.log\n",
      "Start creating features...\n",
      "Start creating features...\n",
      "Start creating features...\n",
      "Start creating features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [15:40<00:00, 78.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=(2459, 784), X_test.shape=(830, 784)\n",
      "X_train.shape=(2459, 784), X_test.shape=(830, 784)\n",
      "X_train.shape=(2459, 784), X_test.shape=(830, 784)\n",
      "X_train.shape=(2459, 784), X_test.shape=(830, 784)\n",
      "y_train.shape=(2459,), y_test.shape=(830,)\n",
      "y_train.shape=(2459,), y_test.shape=(830,)\n",
      "y_train.shape=(2459,), y_test.shape=(830,)\n",
      "y_train.shape=(2459,), y_test.shape=(830,)\n",
      "subject_train.shape=(2459,), subject_test.shape=(830,)\n",
      "subject_train.shape=(2459,), subject_test.shape=(830,)\n",
      "subject_train.shape=(2459,), subject_test.shape=(830,)\n",
      "subject_train.shape=(2459,), subject_test.shape=(830,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# only used to create train and test!!\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from logging import basicConfig, getLogger, StreamHandler, DEBUG\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "CUR_DIR = os.getcwd()\n",
    "DATA_DIR = CUR_DIR\n",
    "ATC_IDS = [1, 2, 3, 4, 5]  # Target activity ids\n",
    "TRAIN_SUBJECTS = [1, 2, 3, 4, 5, 7]\n",
    "TEST_SUBJECTS = [8, 6]\n",
    "\n",
    "# Logging settings\n",
    "EXEC_TIME = \"generate-features-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "LOG_DIR = os.path.join(CUR_DIR, f\"logs/{EXEC_TIME}\")\n",
    "os.makedirs(LOG_DIR, exist_ok=True)  # Create log directory\n",
    "\n",
    "formatter = \"%(levelname)s: %(asctime)s: %(filename)s: %(funcName)s: %(message)s\"\n",
    "basicConfig(filename=f\"{LOG_DIR}/{EXEC_TIME}.log\", level=DEBUG, format=formatter)\n",
    "# Handle logging to both logging and stdout.\n",
    "getLogger().addHandler(StreamHandler(sys.stdout))\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.debug(f\"{LOG_DIR}/{EXEC_TIME}.log\")\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Create features from raw acceleration and gyroscope sensor data, and save features/labels to pickle/npy files\"\"\"\n",
    "    logger.debug(\"Start creating features...\")\n",
    "\n",
    "    # Get file names of raw dataset\n",
    "    acc_files = sorted(glob.glob(os.path.join(DATA_DIR, \"raw data/acc*.txt\")))\n",
    "    gyro_files = sorted(glob.glob(os.path.join(DATA_DIR, \"raw data/gyro*.txt\")))\n",
    "    label_info = pd.read_table(\n",
    "        os.path.join(DATA_DIR, \"raw data/labels.txt\"),\n",
    "        sep=\" \",\n",
    "        header=None,\n",
    "        names=[\"ExpID\", \"UserID\", \"ActID\", \"ActStart\", \"ActEnd\"],\n",
    "    )\n",
    "\n",
    "    X_train, X_test = [], []\n",
    "    subject_train, subject_test = np.array([]), np.array([])\n",
    "    y_train, y_test = np.array([]), np.array([])\n",
    "\n",
    "    # Create features from each row data file\n",
    "    for i in tqdm(range(len(acc_files))):\n",
    "        acc_file, gyro_file = acc_files[i], gyro_files[i]\n",
    "        exp_id = int(acc_file.split(\"exp\")[1][:2])\n",
    "        user_id = int(acc_file.split(\"user\")[1][:2])\n",
    "\n",
    "        temp_label_info = label_info[\n",
    "            (label_info.ExpID == exp_id)\n",
    "            & (label_info.UserID == user_id)\n",
    "            & (label_info.ActID.isin(ATC_IDS))\n",
    "            ]\n",
    "        acc_raw = pd.read_table(acc_file, sep=\" \", header=None, names=[\"x\", \"y\", \"z\"])\n",
    "        gyro_raw = pd.read_table(gyro_file, sep=\" \", header=None, names=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "        for _, us_id, act_id, act_start, act_end in temp_label_info.values:\n",
    "            temp_acc_raw = acc_raw.iloc[act_start : act_end + 1]\n",
    "            temp_gyro_raw = gyro_raw.iloc[act_start : act_end + 1]\n",
    "            features = create_features(temp_acc_raw, temp_gyro_raw)  # Create features\n",
    "            labels = [act_id] * len(features)\n",
    "            subjects = [us_id] * len(features)\n",
    "\n",
    "            if user_id in TRAIN_SUBJECTS:\n",
    "                X_train.append(features)\n",
    "                y_train = np.hstack((y_train, labels))\n",
    "                subject_train = np.hstack((subject_train, subjects))\n",
    "            else:\n",
    "                X_test.append(features)\n",
    "                y_test = np.hstack((y_test, labels))\n",
    "                subject_test = np.hstack((subject_test, subjects))\n",
    "\n",
    "    columns = get_feature_names()\n",
    "    X_train = pd.DataFrame(np.vstack(X_train), columns=columns)\n",
    "    X_test = pd.DataFrame(np.vstack(X_test), columns=columns)\n",
    "\n",
    "    logger.debug(f\"{X_train.shape=}, {X_test.shape=}\")\n",
    "    logger.debug(f\"{y_train.shape=}, {y_test.shape=}\")\n",
    "    logger.debug(f\"{subject_train.shape=}, {subject_test.shape=}\")\n",
    "    # Save features/labels to pickle/npy files\n",
    "    X_train.to_pickle(os.path.join(DATA_DIR, \"my_dataset/X_train.pickle\"))\n",
    "    X_test.to_pickle(os.path.join(DATA_DIR, \"my_dataset/X_test.pickle\"))\n",
    "    np.save(os.path.join(DATA_DIR, \"my_dataset/y_train.npy\"), y_train)\n",
    "    np.save(os.path.join(DATA_DIR, \"my_dataset/y_test.npy\"), y_test)\n",
    "\n",
    "    DATA_DIR2 = os.getcwd()\n",
    "    # Replicate the data set of Test and Train in text style\n",
    "    file_name = \"Test/subject_id_test.txt\"\n",
    "    my_file = open(file_name, 'w')\n",
    "    for row in subject_test:\n",
    "        my_file.write(f\"{int(row)}\\n\")\n",
    "    my_file.close()\n",
    "\n",
    "    file_name = \"Train/y_train.txt\"\n",
    "    my_file = open(file_name, 'w')\n",
    "    for row in y_train:\n",
    "        my_file.write(f\"{int(row)}\\n\")\n",
    "    my_file.close()\n",
    "\n",
    "    file_name = \"Test/y_test.txt\"\n",
    "    my_file = open(file_name, 'w')\n",
    "    for row in y_test:\n",
    "        my_file.write(f\"{int(row)}\\n\")\n",
    "    my_file.close()\n",
    "\n",
    "    with open(\"Test/X_test.txt\", 'a') as f:\n",
    "        dfAsString = X_test.to_string(header=False, index=False)\n",
    "        f.write(dfAsString)\n",
    "\n",
    "    with open(\"Train/X_train.txt\", 'a') as f:\n",
    "        dfAsString = X_train.to_string(header=False, index=False)\n",
    "        f.write(dfAsString)\n",
    "\n",
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}